#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æµ‹è¯•çˆ¬è™«æ•°æ®åº“ä¿å­˜åŠŸèƒ½
æ¨¡æ‹Ÿçˆ¬è™«çš„save_to_databaseæ–¹æ³•
"""

import asyncio
import sys
import os
from datetime import datetime

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
project_root = os.path.dirname(os.path.abspath(__file__))
sys.path.append(project_root)

from services.database_manager import get_db_manager
from loguru import logger

# é…ç½®æ—¥å¿—
logger.remove()
logger.add(
    sys.stderr,
    format="<green>{time:YYYY-MM-DD HH:mm:ss}</green> | <level>{level: <8}</level> | <cyan>{name}</cyan> - <level>{message}</level>",
    level="INFO"
)

async def save_to_database(data: list) -> int:
    """å°†æ•°æ®ä¿å­˜åˆ°æ•°æ®åº“ï¼ˆæ¨¡æ‹Ÿçˆ¬è™«çš„æ–¹æ³•ï¼‰"""
    try:
        if not data:
            logger.warning("æ²¡æœ‰æ•°æ®éœ€è¦ä¿å­˜åˆ°æ•°æ®åº“")
            return 0
        
        logger.info(f"å¼€å§‹ä¿å­˜ {len(data)} æ¡æ•°æ®åˆ°æ•°æ®åº“...")
        
        # è·å–æ•°æ®åº“ç®¡ç†å™¨
        db_manager = get_db_manager()
        logger.info(f"æ•°æ®åº“è·¯å¾„: {db_manager.base_dir}")
        
        # æ’å…¥æ•°æ®ï¼ˆä¼šè‡ªåŠ¨å»é‡ï¼‰
        inserted_count = db_manager.insert_data(data)
        
        logger.info(f"âœ… æˆåŠŸä¿å­˜ {inserted_count} æ¡è®°å½•åˆ°æ•°æ®åº“")
        
        # æ¸…ç†æ—§æ•°æ®åº“ï¼ˆä¿ç•™è¿‘1ä¸ªæœˆï¼‰
        db_manager.cleanup_old_databases(keep_months=1)
        
        return inserted_count
        
    except Exception as e:
        logger.error(f"âŒ ä¿å­˜åˆ°æ•°æ®åº“å¤±è´¥: {e}")
        import traceback
        logger.error(f"é”™è¯¯è¯¦æƒ…: {traceback.format_exc()}")
        return 0

async def test_crawler_save():
    """æµ‹è¯•çˆ¬è™«ä¿å­˜åŠŸèƒ½"""
    logger.info("ğŸ§ª å¼€å§‹æµ‹è¯•çˆ¬è™«æ•°æ®åº“ä¿å­˜åŠŸèƒ½...")
    
    # æ¨¡æ‹Ÿçˆ¬å–åˆ°çš„æ•°æ®
    test_data = [
        {
            'ID': 'crawler_test_001',
            'area': 'æ¸ä¸­åŒº',
            'createDateShow': datetime.now().strftime('%Y-%m-%d'),
            'MDShow': 'çˆ¬è™«æµ‹è¯•é—¨åº—001',
            'totalScore': 88.8,
            'monthlyCanceledRate': '2.5%',
            'dailyCanceledRate': '1.8%',
            'monthlyMerchantRefundRate': '1.2%',
            'monthlyOosRefundRate': '0.6%',
            'monthlyJdOosRate': '0.9%',
            'monthlyBadReviews': '3',
            'monthlyBadReviewRate': '0.3%',
            'monthlyPartialRefundRate': '1.7%',
            'dailyMeituanRating': '4.8',
            'dailyElemeRating': '4.7',
            'dailyMeituanReplyRate': '96%',
            'effectReply': '98%',
            'monthlyMeituanPunctualityRate': '97%',
            'monthlyElemeOntimeRate': '95%',
            'monthlyJdFulfillmentRate': '97%',
            'meituanComprehensiveExperienceDivision': '4.7'
        },
        {
            'ID': 'crawler_test_002',
            'area': 'æ±ŸåŒ—åŒº',
            'createDateShow': datetime.now().strftime('%Y-%m-%d'),
            'MDShow': 'çˆ¬è™«æµ‹è¯•é—¨åº—002',
            'totalScore': 91.2,
            'monthlyCanceledRate': '2.1%',
            'dailyCanceledRate': '1.5%',
            'monthlyMerchantRefundRate': '1.0%',
            'monthlyOosRefundRate': '0.4%',
            'monthlyJdOosRate': '0.7%',
            'monthlyBadReviews': '2',
            'monthlyBadReviewRate': '0.2%',
            'monthlyPartialRefundRate': '1.5%',
            'dailyMeituanRating': '4.9',
            'dailyElemeRating': '4.8',
            'dailyMeituanReplyRate': '98%',
            'effectReply': '99%',
            'monthlyMeituanPunctualityRate': '98%',
            'monthlyElemeOntimeRate': '96%',
            'monthlyJdFulfillmentRate': '98%',
            'meituanComprehensiveExperienceDivision': '4.8'
        }
    ]
    
    # ä¿å­˜æ•°æ®
    result = await save_to_database(test_data)
    
    if result > 0:
        logger.info(f"ğŸ‰ çˆ¬è™«æ•°æ®åº“ä¿å­˜æµ‹è¯•æˆåŠŸï¼ä¿å­˜äº† {result} æ¡è®°å½•")
        
        # éªŒè¯æ•°æ®
        db_manager = get_db_manager()
        query_result = db_manager.query_data(mdshow_filter="çˆ¬è™«æµ‹è¯•", page=1, page_size=10)
        logger.info(f"ğŸ“Š éªŒè¯æŸ¥è¯¢: æ‰¾åˆ° {query_result['total']} æ¡çˆ¬è™«æµ‹è¯•è®°å½•")
        
        return True
    else:
        logger.error("âŒ çˆ¬è™«æ•°æ®åº“ä¿å­˜æµ‹è¯•å¤±è´¥")
        return False

if __name__ == "__main__":
    asyncio.run(test_crawler_save())
