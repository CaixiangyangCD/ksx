#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
KSXç½‘ç«™çˆ¬è™«æ¨¡å— - APIç‰ˆæœ¬
ä½¿ç”¨Playwrightå®ç°ç½‘ç«™ç™»å½•å’ŒAPIæ•°æ®çˆ¬å–åŠŸèƒ½
"""

import asyncio
import json
import csv
from datetime import datetime, timedelta
from pathlib import Path
from typing import Optional, Dict, Any, List
from playwright.async_api import async_playwright, Browser, Page, BrowserContext, Response
from playwright.async_api import TimeoutError as PlaywrightTimeoutError
from loguru import logger
import sys
import os

# è®¾ç½®æµè§ˆå™¨è·¯å¾„åˆ°é¡¹ç›®ç›®å½•
project_root = os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
browser_path = os.path.join(project_root, "playwright-browsers")
os.environ["PLAYWRIGHT_BROWSERS_PATH"] = browser_path

# è‡ªåŠ¨æ£€æŸ¥å’Œå®‰è£…æµè§ˆå™¨
def ensure_browser_environment():
    """ç¡®ä¿æµè§ˆå™¨ç¯å¢ƒå·²æ­£ç¡®è®¾ç½®"""
    try:
        from services.browser_manager import setup_browser_environment
        if not setup_browser_environment(project_root):
            logger.error("æµè§ˆå™¨ç¯å¢ƒè®¾ç½®å¤±è´¥")
            return False
        return True
    except Exception as e:
        logger.error(f"è®¾ç½®æµè§ˆå™¨ç¯å¢ƒæ—¶å‘ç”Ÿé”™è¯¯: {e}")
        return False

# åœ¨å¯¼å…¥æ—¶è‡ªåŠ¨æ£€æŸ¥æµè§ˆå™¨ç¯å¢ƒ
if not ensure_browser_environment():
    logger.warning("æµè§ˆå™¨ç¯å¢ƒæ£€æŸ¥å¤±è´¥ï¼Œå°†ä½¿ç”¨ç³»ç»Ÿé»˜è®¤è·¯å¾„")
    os.environ.pop("PLAYWRIGHT_BROWSERS_PATH", None)

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„ï¼Œä»¥ä¾¿å¯¼å…¥servicesæ¨¡å—
project_root = os.path.dirname(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))
sys.path.append(project_root)
from services.database_manager import get_db_manager
from services.config_database_manager import config_db_manager


class KSXCrawler:
    """KSXç½‘ç«™çˆ¬è™«ç±» - APIç‰ˆæœ¬"""
    
    def __init__(self, headless: bool = False, timeout: int = None, target_date: str = None):
        """
        åˆå§‹åŒ–çˆ¬è™«
        
        Args:
            headless: æ˜¯å¦æ— å¤´æ¨¡å¼è¿è¡Œæµè§ˆå™¨
            timeout: è¶…æ—¶æ—¶é—´ï¼ˆæ¯«ç§’ï¼‰ï¼Œå¦‚æœä¸ºNoneåˆ™ä»é…ç½®æ–‡ä»¶è¯»å–
            target_date: ç›®æ ‡æ—¥æœŸ (YYYY-MM-DD)ï¼Œå¦‚æœä¸ºNoneåˆ™ä½¿ç”¨é»˜è®¤æ—¥æœŸ
        """
        self.headless = headless
        self.target_date = target_date
        
        # ä»é…ç½®æ–‡ä»¶è¯»å–è¶…æ—¶æ—¶é—´
        if timeout is None:
            try:
                from config import WEBSITE_CONFIG
                self.timeout = WEBSITE_CONFIG['timeout']
            except ImportError:
                self.timeout = 30000  # é»˜è®¤30ç§’
        else:
            self.timeout = timeout
        self.browser: Optional[Browser] = None
        self.context: Optional[BrowserContext] = None
        self.page: Optional[Page] = None
        
        # é…ç½®æ—¥å¿—
        self._setup_logging()
        
        # ç™»å½•ä¿¡æ¯
        self.login_url = "https://ksx.dahuafuli.com:8306/"
        # ä»é…ç½®æ–‡ä»¶è¯»å–ç”¨æˆ·åå’Œå¯†ç 
        try:
            # å°è¯•ä¸åŒçš„å¯¼å…¥æ–¹å¼
            try:
                from config import LOGIN_CONFIG
            except ImportError:
                from .config import LOGIN_CONFIG
            
            self.username = LOGIN_CONFIG['username']
            self.password = LOGIN_CONFIG['password']
        except ImportError:
            # å¦‚æœé…ç½®æ–‡ä»¶ä¸å­˜åœ¨ï¼Œä½¿ç”¨é»˜è®¤å€¼
            self.username = "fsrm001"
            self.password = "fsrm001"
        
        # ç½‘ç»œè¯·æ±‚æ•°æ®å­˜å‚¨
        self.api_responses = []
        self.current_page_data = None
        self.page_info = None
        
    def _setup_logging(self):
        """é…ç½®æ—¥å¿—ç³»ç»Ÿ - ä½¿ç”¨loguru"""
        # æ¸…é™¤é»˜è®¤çš„logger
        logger.remove()
        
        # æ·»åŠ æ§åˆ¶å°è¾“å‡º
        logger.add(
            sys.stderr,
            format="<green>{time:YYYY-MM-DD HH:mm:ss}</green> | <level>{level: <8}</level> | <cyan>{name}</cyan>:<cyan>{function}</cyan>:<cyan>{line}</cyan> - <level>{message}</level>",
            level="INFO"
        )
        
        # æ·»åŠ æ–‡ä»¶è¾“å‡ºï¼ŒæŒ‰æ—¥æœŸè½®è½¬ï¼Œä¿ç•™è¿‘30å¤©
        logger.add(
            "logs/crawler_{time:YYYY-MM-DD}.log",
            format="{time:YYYY-MM-DD HH:mm:ss} | {level: <8} | {name}:{function}:{line} - {message}",
            level="DEBUG",
            rotation="1 day",
            retention="30 days",
            compression="zip",
            encoding="utf-8"
        )
        
        # åˆ›å»ºlogsç›®å½•
        Path("logs").mkdir(exist_ok=True)
        
        self.logger = logger
    
    async def _setup_request_interception(self):
        """è®¾ç½®ç½‘ç»œè¯·æ±‚æ‹¦æˆª"""
        if not self.page:
            self.logger.error("é¡µé¢æœªåˆå§‹åŒ–ï¼Œæ— æ³•è®¾ç½®è¯·æ±‚æ‹¦æˆª")
            return
            
        # ç›‘å¬å“åº”
        self.page.on("response", self._handle_response)
        self.logger.info("âœ… ç½‘ç»œè¯·æ±‚æ‹¦æˆªå·²è®¾ç½®")
    
    async def _handle_response(self, response: Response):
        """å¤„ç†ç½‘ç»œå“åº”"""
        try:
            # åªå¤„ç†UIProcessorç›¸å…³çš„è¯·æ±‚
            if "/UIProcessor" in response.url:
                self.logger.info(f"ğŸ” æ‹¦æˆªåˆ°UIProcessorè¯·æ±‚: {response.url}")
                
                # è·å–å“åº”å†…å®¹
                if response.status == 200:
                    try:
                        response_data = await response.json()
                        self.logger.info(f"ğŸ“¦ UIProcessorå“åº”çŠ¶æ€: {response.status}")
                        
                        # æ£€æŸ¥å“åº”æ ¼å¼
                        if isinstance(response_data, dict) and 'success' in response_data:
                            if response_data.get('success'):
                                data = response_data.get('data', [])
                                page_info = response_data.get('pageInfo', {})
                                
                                self.logger.info(f"âœ… æˆåŠŸè·å–æ•°æ®: {len(data)} æ¡è®°å½•")
                                self.logger.info(f"ğŸ“„ åˆ†é¡µä¿¡æ¯: {page_info}")
                                
                                # å­˜å‚¨æ•°æ®
                                self.current_page_data = data
                                self.page_info = page_info
                                self.api_responses.append({
                                    'url': response.url,
                                    'data': data,
                                    'pageInfo': page_info,
                                    'timestamp': datetime.now()
                                })
                            else:
                                self.logger.warning(f"âŒ UIProcessorè¯·æ±‚å¤±è´¥: {response_data}")
                        else:
                            self.logger.warning(f"âš ï¸ æ„å¤–çš„å“åº”æ ¼å¼: {response_data}")
                            
                    except Exception as e:
                        self.logger.error(f"âŒ è§£æUIProcessorå“åº”å¤±è´¥: {e}")
                        # å°è¯•è·å–æ–‡æœ¬å†…å®¹
                        try:
                            text_content = await response.text()
                            self.logger.info(f"ğŸ“ å“åº”æ–‡æœ¬å†…å®¹: {text_content[:500]}...")
                        except Exception:
                            pass
                else:
                    self.logger.warning(f"âš ï¸ UIProcessorè¯·æ±‚çŠ¶æ€ç : {response.status}")
                    
        except Exception as e:
            self.logger.error(f"âŒ å¤„ç†å“åº”æ—¶å‡ºé”™: {e}")
    
    async def start_browser(self):
        """å¯åŠ¨æµè§ˆå™¨"""
        try:
            # ç¡®ä¿æ­£ç¡®åˆå§‹åŒ– playwright
            self.playwright = await async_playwright().start()
            if not self.playwright:
                raise Exception("Playwright åˆå§‹åŒ–å¤±è´¥")
            
            # å¯åŠ¨æµè§ˆå™¨ - ä½¿ç”¨Chrome Beta
            self.browser = await self.playwright.chromium.launch(
                headless=self.headless,
                channel="chrome-beta",  # ä½¿ç”¨Chrome Beta
                args=[
                    '--no-sandbox',
                    '--disable-setuid-sandbox',
                    '--disable-dev-shm-usage',
                    '--disable-accelerated-2d-canvas',
                    '--no-first-run',
                    '--no-zygote',
                    '--disable-gpu'
                ]
            )
            
            if not self.browser:
                raise Exception("æµè§ˆå™¨å¯åŠ¨å¤±è´¥")
            
            # åˆ›å»ºä¸Šä¸‹æ–‡
            self.context = await self.browser.new_context(
                viewport={'width': 1920, 'height': 1080},
                user_agent='Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'
            )
            
            if not self.context:
                raise Exception("æµè§ˆå™¨ä¸Šä¸‹æ–‡åˆ›å»ºå¤±è´¥")
            
            # åˆ›å»ºé¡µé¢
            self.page = await self.context.new_page()
            if not self.page:
                raise Exception("é¡µé¢åˆ›å»ºå¤±è´¥")
                
            # set_default_timeout æ˜¯åŒæ­¥æ–¹æ³•ï¼Œä¸éœ€è¦ await
            self.page.set_default_timeout(self.timeout)
            
            # è®¾ç½®ç½‘ç»œè¯·æ±‚æ‹¦æˆª
            await self._setup_request_interception()
            
            self.logger.info("æµè§ˆå™¨å¯åŠ¨æˆåŠŸ")
            return True
            
        except Exception as e:
            self.logger.error(f"å¯åŠ¨æµè§ˆå™¨å¤±è´¥: {e}")
            # æ¸…ç†å·²åˆ›å»ºçš„èµ„æº
            try:
                await self.close()
            except Exception:
                pass
            return False
    
    async def navigate_to_login(self) -> bool:
        """å¯¼èˆªåˆ°ç™»å½•é¡µé¢"""
        try:
            self.logger.info("æ­£åœ¨å¯¼èˆªåˆ°ç™»å½•é¡µé¢...")
            self.logger.info(f"æ­£åœ¨è®¿é—®ç™»å½•é¡µé¢: {self.login_url}")
            
            await self.page.goto(self.login_url)
            await self.page.wait_for_load_state('networkidle')
            
            self.logger.info("æˆåŠŸè®¿é—®ç™»å½•é¡µé¢")
            return True
            
        except Exception as e:
            self.logger.error(f"å¯¼èˆªåˆ°ç™»å½•é¡µé¢å¤±è´¥: {e}")
            return False
    
    async def find_login_elements(self) -> Dict[str, Any]:
        """æŸ¥æ‰¾ç™»å½•é¡µé¢å…ƒç´ """
        try:
            self.logger.info("æ­£åœ¨æŸ¥æ‰¾ç™»å½•å…ƒç´ ...")
            
            # æŸ¥æ‰¾ç”¨æˆ·åè¾“å…¥æ¡†
            username_input = await self.page.wait_for_selector('input[name="userId"]', timeout=10000)
            if not username_input:
                raise Exception("æœªæ‰¾åˆ°ç”¨æˆ·åè¾“å…¥æ¡†")
            
            # æŸ¥æ‰¾å¯†ç è¾“å…¥æ¡†
            password_input = await self.page.wait_for_selector('input[name="pass"]', timeout=5000)
            if not password_input:
                raise Exception("æœªæ‰¾åˆ°å¯†ç è¾“å…¥æ¡†")
            
            # æŸ¥æ‰¾ç™»å½•æŒ‰é’®
            login_button = await self.page.wait_for_selector('button[type="submit"]', timeout=5000)
            if not login_button:
                raise Exception("æœªæ‰¾åˆ°ç™»å½•æŒ‰é’®")
            
            self.logger.info("æˆåŠŸæ‰¾åˆ°æ‰€æœ‰ç™»å½•å…ƒç´ ")
            return {
                'username_input': username_input,
                'password_input': password_input,
                'login_button': login_button
            }
            
        except Exception as e:
            self.logger.error(f"æŸ¥æ‰¾ç™»å½•å…ƒç´ å¤±è´¥: {e}")
            return {}
    
    async def perform_login(self, elements: Dict[str, Any]) -> bool:
        """æ‰§è¡Œç™»å½•æ“ä½œ"""
        try:
            # æ¸…ç©ºè¾“å…¥æ¡†å¹¶è¾“å…¥ç”¨æˆ·å
            await elements['username_input'].fill('')
            await elements['username_input'].type(self.username, delay=100)
            self.logger.info(f"è¾“å…¥ç”¨æˆ·å: {self.username}")
            
            # æ¸…ç©ºè¾“å…¥æ¡†å¹¶è¾“å…¥å¯†ç 
            await elements['password_input'].fill('')
            await elements['password_input'].type(self.password, delay=100)
            self.logger.info(f"è¾“å…¥å¯†ç : {self.password}")
            
            # ç‚¹å‡»ç™»å½•æŒ‰é’®
            await elements['login_button'].click()
            self.logger.info("ç‚¹å‡»ç™»å½•æŒ‰é’®")
            
            # ç­‰å¾…é¡µé¢å“åº”
            await self.page.wait_for_load_state('networkidle')
            await asyncio.sleep(3)  # é¢å¤–ç­‰å¾…ç¡®ä¿é¡µé¢å®Œå…¨åŠ è½½
            
            return True
            
        except Exception as e:
            self.logger.error(f"æ‰§è¡Œç™»å½•æ“ä½œå¤±è´¥: {e}")
            return False
    
    async def verify_login_success(self) -> bool:
        """éªŒè¯ç™»å½•æ˜¯å¦æˆåŠŸ - ç®€åŒ–ç‰ˆæœ¬ï¼Œç›´æ¥è¿”å›True"""
        try:
            # ç­‰å¾…ä¸€ä¸‹è®©é¡µé¢åŠ è½½
            await asyncio.sleep(2)
            self.logger.info("è·³è¿‡ç™»å½•éªŒè¯ï¼Œå‡è®¾ç™»å½•æˆåŠŸ")
            return True
        except Exception as e:
            self.logger.error(f"ç™»å½•éªŒè¯å¼‚å¸¸: {e}")
            return True
    
    async def login(self) -> bool:
        """å®Œæ•´çš„ç™»å½•æµç¨‹"""
        try:
            self.logger.info("å¼€å§‹ç™»å½•æµç¨‹...")
            
            # æ£€æŸ¥æµè§ˆå™¨æ˜¯å¦å·²å¯åŠ¨ï¼Œå¦‚æœæ²¡æœ‰åˆ™å¯åŠ¨
            if not self.browser or not self.page:
                if not await self.start_browser():
                    return False
            
            # å¯¼èˆªåˆ°ç™»å½•é¡µé¢
            if not await self.navigate_to_login():
                return False
            
            # æŸ¥æ‰¾ç™»å½•å…ƒç´ 
            elements = await self.find_login_elements()
            if not elements:
                return False
            
            # æ‰§è¡Œç™»å½•
            self.logger.info("æ­£åœ¨æ‰§è¡Œç™»å½•æ“ä½œ...")
            if not await self.perform_login(elements):
                return False
            
            # éªŒè¯ç™»å½•ç»“æœ
            login_success = await self.verify_login_success()
            
            self.logger.info("ç™»å½•æµç¨‹å®Œæˆ")
            return login_success
            
        except Exception as e:
            self.logger.error(f"ç™»å½•å¤±è´¥: {e}")
            return False
    
    async def set_date_and_search(self) -> bool:
        """è®¾ç½®æ—¥æœŸå¹¶æ‰§è¡Œæœç´¢"""
        try:
            self.logger.info("æ­£åœ¨è®¾ç½®æ—¥æœŸå¹¶æ‰§è¡Œæœç´¢...")
            
            # ç‚¹å‡»å±•å¼€æŒ‰é’®
            self.logger.info("æ­£åœ¨æŸ¥æ‰¾å¹¶ç‚¹å‡»å±•å¼€æŒ‰é’®...")
            expand_button = await self.page.wait_for_selector('button.lb-LBObjectParameterFormExpandButton-root', timeout=10000)
            if not expand_button:
                self.logger.error("æœªæ‰¾åˆ°å±•å¼€æŒ‰é’®")
                return False
            
            await expand_button.click()
            self.logger.info("ç‚¹å‡»å±•å¼€æŒ‰é’®æˆåŠŸ")
            await asyncio.sleep(1)  # ç­‰å¾…å±•å¼€åŠ¨ç”»å®Œæˆ
            
            # æŸ¥æ‰¾æ‰€æœ‰æ—¥æœŸè¾“å…¥æ¡†
            self.logger.info("æ­£åœ¨æŸ¥æ‰¾æ—¥æœŸè¾“å…¥æ¡†...")
            date_inputs = await self.page.query_selector_all('input.lb-LBDatePicker-input[type="text"]')
            if not date_inputs or len(date_inputs) < 2:
                self.logger.error(f"æœªæ‰¾åˆ°è¶³å¤Ÿçš„æ—¥æœŸè¾“å…¥æ¡†ï¼Œæ‰¾åˆ° {len(date_inputs) if date_inputs else 0} ä¸ª")
                return False
            
            # è®¡ç®—ç›®æ ‡æ—¥æœŸ
            if self.target_date:
                # ä½¿ç”¨æŒ‡å®šçš„ç›®æ ‡æ—¥æœŸ
                date_str = self.target_date
                self.logger.info(f"ä½¿ç”¨æŒ‡å®šçš„ç›®æ ‡æ—¥æœŸ: {date_str}")
            else:
                # ä½¿ç”¨é»˜è®¤æ—¥æœŸï¼ˆå‰å¤©çš„æ—¥æœŸï¼Œ9æœˆ6æ—¥æœ‰æ•°æ®ï¼‰
                yesterday = datetime.now() - timedelta(days=2)
                date_str = yesterday.strftime('%Y-%m-%d')
                self.logger.info(f"ä½¿ç”¨é»˜è®¤æ—¥æœŸ: {date_str}")
            
            # è®¾ç½®å¼€å§‹æ—¥æœŸï¼ˆç¬¬ä¸€ä¸ªè¾“å…¥æ¡†ï¼‰
            start_date_input = date_inputs[0]
            await start_date_input.fill('')
            await start_date_input.type(date_str, delay=100)
            self.logger.info(f"è®¾ç½®å¼€å§‹æ—¥æœŸä¸º: {date_str}")
            
            # è®¾ç½®ç»“æŸæ—¥æœŸï¼ˆç¬¬äºŒä¸ªè¾“å…¥æ¡†ï¼‰
            end_date_input = date_inputs[1]
            await end_date_input.fill('')
            await end_date_input.type(date_str, delay=100)
            self.logger.info(f"è®¾ç½®ç»“æŸæ—¥æœŸä¸º: {date_str}")
            
            # æŸ¥æ‰¾å¹¶ç‚¹å‡»æœç´¢æŒ‰é’®
            search_button = await self.page.wait_for_selector('button.lb-LBButton-contained', timeout=5000)
            if not search_button:
                self.logger.error("æœªæ‰¾åˆ°æœç´¢æŒ‰é’®")
                return False
            
            await search_button.click()
            self.logger.info("ç‚¹å‡»æœç´¢æŒ‰é’®")
            
            # ç­‰å¾…æœç´¢ç»“æœ
            await self.page.wait_for_load_state('networkidle')
            await asyncio.sleep(1)  # å‡å°‘ç­‰å¾…æ—¶é—´
            
            # ç­‰å¾…APIå“åº”æ•°æ®
            self.logger.info("ç­‰å¾…APIå“åº”æ•°æ®...")
            await asyncio.sleep(2)  # ç»™APIå“åº”ä¸€äº›æ—¶é—´
            
            self.logger.info("æœç´¢å®Œæˆ")
            return True
            
        except Exception as e:
            self.logger.error(f"è®¾ç½®æ—¥æœŸå¹¶æœç´¢å¤±è´¥: {e}")
            return False
    
    async def extract_data_from_api(self) -> dict:
        """ä»æ‹¦æˆªçš„APIå“åº”ä¸­æå–æ•°æ®"""
        try:
            self.logger.info("æ­£åœ¨ç­‰å¾…APIå“åº”æ•°æ®...")
            
            # ç­‰å¾…APIå“åº”æ•°æ®
            max_wait_time = 5  # å‡å°‘ç­‰å¾…æ—¶é—´åˆ°5ç§’
            wait_interval = 0.2  # æ›´é¢‘ç¹çš„æ£€æŸ¥ï¼Œæ¯0.2ç§’æ£€æŸ¥ä¸€æ¬¡
            waited_time = 0
            
            while waited_time < max_wait_time:
                if self.current_page_data is not None and self.page_info is not None:
                    self.logger.info(f"âœ… è·å–åˆ°APIæ•°æ®: {len(self.current_page_data)} æ¡è®°å½•")
                    self.logger.info(f"ğŸ“„ åˆ†é¡µä¿¡æ¯: {self.page_info}")
                    
                    return {
                        'data': self.current_page_data,
                        'pageInfo': self.page_info,
                        'success': True
                    }
                
                await asyncio.sleep(wait_interval)
                waited_time += wait_interval
            
            # å¦‚æœè¶…æ—¶ï¼Œæ£€æŸ¥æ˜¯å¦æœ‰éƒ¨åˆ†æ•°æ®
            if self.current_page_data is not None:
                self.logger.warning("â° ç­‰å¾…åˆ†é¡µä¿¡æ¯è¶…æ—¶ï¼Œä½†å·²æœ‰æ•°æ®")
                return {
                    'data': self.current_page_data,
                    'pageInfo': self.page_info or {},
                    'success': True
                }
            
            self.logger.warning("â° ç­‰å¾…APIå“åº”è¶…æ—¶")
            return {
                'data': [],
                'pageInfo': {},
                'success': False,
                'error': 'APIå“åº”è¶…æ—¶'
            }
            
        except Exception as e:
            self.logger.error(f"âŒ ä»APIæå–æ•°æ®å¤±è´¥: {e}")
            return {
                'data': [],
                'pageInfo': {},
                'success': False,
                'error': str(e)
            }
    
    async def extract_all_pages_data_from_api(self) -> list:
        """ä½¿ç”¨APIæ•°æ®æå–æ‰€æœ‰é¡µé¢æ•°æ®"""
        try:
            self.logger.info("ğŸš€ å¼€å§‹åŸºäºAPIçš„æ•°æ®æå–...")
            all_data = []
            current_page = 1
            total_pages = 0
            total_records = 0
            seen_ids = set()  # ç”¨äºæ£€æŸ¥é‡å¤æ•°æ®
            
            while True:
                self.logger.info(f"ğŸ“„ æ­£åœ¨å¤„ç†ç¬¬ {current_page} é¡µ...")
                
                # å¦‚æœä¸æ˜¯ç¬¬ä¸€é¡µï¼Œéœ€è¦ç‚¹å‡»ä¸‹ä¸€é¡µ
                if current_page > 1:
                    # æ¸…ç©ºä¹‹å‰çš„æ•°æ®ï¼ˆåªåœ¨ç¿»é¡µæ—¶æ¸…ç©ºï¼‰
                    self.current_page_data = None
                    self.page_info = None
                    
                    click_result = await self.click_next_page_api()
                    if not click_result:
                        self.logger.info("âœ… å·²åˆ°è¾¾æœ€åä¸€é¡µï¼Œåœæ­¢æ•°æ®æå–")
                        break
                    
                    # ç­‰å¾…å¹¶è·å–APIæ•°æ®
                    api_result = await self.extract_data_from_api()
                else:
                    # ç¬¬ä¸€é¡µä½¿ç”¨å·²æœ‰çš„æ•°æ®
                    if self.current_page_data is not None and self.page_info is not None:
                        self.logger.info(f"âœ… ä½¿ç”¨å·²æœ‰çš„ç¬¬ä¸€é¡µæ•°æ®: {len(self.current_page_data)} æ¡è®°å½•")
                        api_result = {
                            'data': self.current_page_data,
                            'pageInfo': self.page_info,
                            'success': True
                        }
                    else:
                        # å¦‚æœæ²¡æœ‰æ•°æ®ï¼Œç­‰å¾…å¹¶è·å–APIæ•°æ®
                        api_result = await self.extract_data_from_api()
                
                if not api_result['success']:
                    self.logger.error(f"âŒ ç¬¬ {current_page} é¡µAPIæ•°æ®è·å–å¤±è´¥: {api_result.get('error', 'æœªçŸ¥é”™è¯¯')}")
                    break
                
                page_data = api_result['data']
                page_info = api_result['pageInfo']
                
                # è®°å½•åˆ†é¡µä¿¡æ¯
                if current_page == 1:
                    total_records = page_info.get('total', 0)
                    page_size = page_info.get('pageSize', 50)
                    total_pages = (total_records + page_size - 1) // page_size
                    self.logger.info(f"ğŸ“Š æ•°æ®ç»Ÿè®¡: æ€»è®¡ {total_records} æ¡è®°å½•ï¼Œå…± {total_pages} é¡µ")
                
                # æ£€æŸ¥æ•°æ®æ˜¯å¦é‡å¤
                if page_data:
                    new_count = 0
                    for item in page_data:
                        item_id = item.get('ID')
                        if item_id and item_id not in seen_ids:
                            seen_ids.add(item_id)
                            new_count += 1
                    
                    if new_count == 0:
                        self.logger.warning(f"âš ï¸ ç¬¬ {current_page} é¡µ: æ‰€æœ‰æ•°æ®éƒ½æ˜¯é‡å¤çš„ï¼Œåœæ­¢æå–")
                        break
                    
                    all_data.extend(page_data)
                    self.logger.info(f"âœ… ç¬¬ {current_page} é¡µ: æ–°å¢ {len(page_data)} æ¡è®°å½•ï¼ˆå…¶ä¸­ {new_count} æ¡æ–°æ•°æ®ï¼‰ï¼Œç´¯è®¡ {len(all_data)} æ¡")
                else:
                    self.logger.warning(f"âš ï¸ ç¬¬ {current_page} é¡µ: æ²¡æœ‰æ•°æ®")
                    break
                
                # æ£€æŸ¥æ˜¯å¦è¿˜æœ‰æ›´å¤šé¡µ
                has_more = page_info.get('hasMore', False)
                if not has_more:
                    self.logger.info("âœ… æ ¹æ®APIè¿”å›çš„hasMore=falseï¼Œå·²åˆ°è¾¾æœ€åä¸€é¡µ")
                    break
                
                # æ£€æŸ¥å½“å‰é¡µå·æ˜¯å¦è¶…è¿‡æ€»é¡µæ•°
                current_page_no = page_info.get('pageNo', current_page)
                if current_page_no >= total_pages:
                    self.logger.info(f"âœ… å½“å‰é¡µå· {current_page_no} å·²è¾¾åˆ°æ€»é¡µæ•° {total_pages}ï¼Œåœæ­¢æå–")
                    break
                
                # å®‰å…¨æ£€æŸ¥ï¼šé¿å…æ— é™å¾ªç¯
                if current_page >= 20:  # æœ€å¤š20é¡µ
                    self.logger.info(f"ğŸ›‘ è¾¾åˆ°æœ€å¤§é¡µæ•°é™åˆ¶ ({current_page})ï¼Œåœæ­¢æå–")
                    break
                
                current_page += 1
                
                # é¡µé¢é—´ç­‰å¾…
                await asyncio.sleep(1)
            
            self.logger.info(f"ğŸ‰ æ•°æ®æå–å®Œæˆï¼æ€»è®¡è·å– {len(all_data)} æ¡è®°å½•ï¼Œå”¯ä¸€è®°å½• {len(seen_ids)} æ¡")
            return all_data
            
        except Exception as e:
            self.logger.error(f"âŒ APIæ•°æ®æå–è¿‡ç¨‹å‡ºé”™: {e}")
            return []
    
    async def click_next_page_api(self) -> bool:
        """ç‚¹å‡»ä¸‹ä¸€é¡µï¼ˆç”¨äºAPIæ•°æ®æå–ï¼‰"""
        try:
            self.logger.info("ğŸ“„ æ­£åœ¨ç‚¹å‡»ä¸‹ä¸€é¡µ...")
            
            # æŸ¥æ‰¾åˆ†é¡µå®¹å™¨
            pagination_container = await self.page.wait_for_selector('ul.lb-MuiPagination-ul', timeout=5000)
            if not pagination_container:
                self.logger.warning("âŒ æœªæ‰¾åˆ°åˆ†é¡µå®¹å™¨")
                return False
            
            # è·å–æ‰€æœ‰åˆ†é¡µé¡¹
            page_items = await pagination_container.query_selector_all('li')
            if not page_items or len(page_items) < 2:
                self.logger.warning("âŒ åˆ†é¡µé¡¹ä¸è¶³")
                return False
            
            # æ‰¾åˆ°ä¸‹ä¸€é¡µæŒ‰é’®ï¼ˆé€šå¸¸æ˜¯æœ€åä¸€ä¸ªliï¼‰
            next_button_li = page_items[-1]
            next_button = await next_button_li.query_selector('button')
            
            if not next_button:
                self.logger.warning("âŒ æœªæ‰¾åˆ°ä¸‹ä¸€é¡µæŒ‰é’®")
                return False
            
            # æ£€æŸ¥æŒ‰é’®æ˜¯å¦å¯ç‚¹å‡»
            is_disabled = await next_button.get_attribute('disabled')
            if is_disabled:
                self.logger.info("âœ… ä¸‹ä¸€é¡µæŒ‰é’®å·²ç¦ç”¨ï¼Œåˆ°è¾¾æœ€åä¸€é¡µ")
                return False
            
            # æ£€æŸ¥æŒ‰é’®æ˜¯å¦å¯è§
            is_visible = await next_button.is_visible()
            if not is_visible:
                self.logger.warning("âŒ ä¸‹ä¸€é¡µæŒ‰é’®ä¸å¯è§")
                return False
            
            # ç‚¹å‡»ä¸‹ä¸€é¡µ
            await next_button.click()
            self.logger.info("âœ… æˆåŠŸç‚¹å‡»ä¸‹ä¸€é¡µ")
            
            # ç­‰å¾…é¡µé¢æ›´æ–°
            await asyncio.sleep(2)
            
            return True
            
        except Exception as e:
            self.logger.error(f"âŒ ç‚¹å‡»ä¸‹ä¸€é¡µå¤±è´¥: {e}")
            return False
    
    async def save_api_data_to_csv(self, data: list, filename: str = None) -> str:
        """
        å°†APIæ•°æ®ä¿å­˜åˆ°CSVæ–‡ä»¶
        
        æ³¨æ„ï¼šæ­¤åŠŸèƒ½å·²æš‚æ—¶æ³¨é‡Šï¼Œå¦‚éœ€å¯ç”¨è¯·å–æ¶ˆç›¸å…³ä»£ç çš„æ³¨é‡Š
        """
        try:
            if not data:
                self.logger.warning("æ²¡æœ‰æ•°æ®å¯ä¿å­˜")
                return ""
            
            # ç”Ÿæˆæ–‡ä»¶å
            if not filename:
                timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
                filename = f"ksx_api_data_{timestamp}.csv"
            
            # ç¡®ä¿dataç›®å½•å­˜åœ¨
            data_dir = Path("data")
            data_dir.mkdir(exist_ok=True)
            
            filepath = data_dir / filename
            
            # å¦‚æœæ•°æ®æ˜¯å­—å…¸åˆ—è¡¨ï¼Œç›´æ¥ä¿å­˜
            if data and isinstance(data[0], dict):
                # è·å–æ‰€æœ‰å¯èƒ½çš„å­—æ®µå
                all_fields = set()
                for item in data:
                    all_fields.update(item.keys())
                
                all_fields = sorted(list(all_fields))
                
                with open(filepath, 'w', newline='', encoding='utf-8-sig') as csvfile:
                    writer = csv.DictWriter(csvfile, fieldnames=all_fields)
                    writer.writeheader()
                    
                    for item in data:
                        writer.writerow(item)
                
                self.logger.info(f"âœ… APIæ•°æ®å·²ä¿å­˜åˆ°: {filepath}")
                self.logger.info(f"ğŸ“Š ä¿å­˜è®°å½•æ•°: {len(data)}")
                self.logger.info(f"ğŸ“„ å­—æ®µæ•°: {len(all_fields)}")
                self.logger.info(f"ğŸ”‘ å­—æ®µåˆ—è¡¨: {all_fields}")
                
                return str(filepath)
            else:
                self.logger.error("âŒ æ•°æ®æ ¼å¼ä¸æ”¯æŒ")
                return ""
                
        except Exception as e:
            self.logger.error(f"âŒ ä¿å­˜CSVæ–‡ä»¶å¤±è´¥: {e}")
            return ""
    
    async def sync_stores_to_config(self, data: list):
        """
        åŒæ­¥é—¨åº—åˆ°é…ç½®æ•°æ®åº“
        
        Args:
            data: æ•°æ®åˆ—è¡¨
        """
        try:
            if not data:
                return
            
            # æå–æ‰€æœ‰å”¯ä¸€çš„é—¨åº—åç§°
            store_names = set()
            for item in data:
                if isinstance(item, dict):
                    # å°è¯•å¤šä¸ªå¯èƒ½çš„å­—æ®µå
                    store_name = item.get('store_name') or item.get('MDShow') or item.get('mdshow')
                    if store_name and store_name.strip():
                        # æ¸…ç†HTMLæ ‡ç­¾
                        import re
                        clean_name = re.sub(r'<[^>]+>', '', store_name.strip())
                        if clean_name:
                            store_names.add(clean_name)
            
            # æ·»åŠ åˆ°é…ç½®æ•°æ®åº“
            new_stores_count = 0
            for store_name in store_names:
                if config_db_manager.add_store(store_name):
                    new_stores_count += 1
            
            if new_stores_count > 0:
                self.logger.info(f"ğŸ†• æ–°å¢ {new_stores_count} ä¸ªé—¨åº—åˆ°é…ç½®æ•°æ®åº“")
            else:
                self.logger.info(f"ğŸ“‹ é—¨åº—é…ç½®æ•°æ®åº“å·²æ˜¯æœ€æ–°çŠ¶æ€")
                
        except Exception as e:
            self.logger.error(f"âŒ åŒæ­¥é—¨åº—åˆ°é…ç½®æ•°æ®åº“å¤±è´¥: {e}")
    
    async def smart_data_extraction(self, current_db_count: int) -> Dict[str, Any]:
        """æ™ºèƒ½æ•°æ®æå–æµç¨‹ - æ ¹æ®å½“å‰æ•°æ®åº“æ•°æ®é‡å†³å®šæ˜¯å¦éœ€è¦åŒæ­¥"""
        try:
            self.logger.info(f"ğŸ§  å¼€å§‹æ™ºèƒ½æ•°æ®æå–ï¼Œå½“å‰æ•°æ®åº“æœ‰ {current_db_count} æ¡æ•°æ®...")
            
            # æ‰§è¡Œæœç´¢
            search_result = await self.set_date_and_search()
            if not search_result:
                self.logger.error("âŒ æœç´¢å¤±è´¥")
                return {"success": False, "action": "error", "message": "æœç´¢å¤±è´¥"}
            
            # è·å–ç¬¬ä¸€é¡µæ•°æ®æ¥æ£€æŸ¥æ€»æ•°
            self.logger.info("ğŸ“„ è·å–ç¬¬ä¸€é¡µæ•°æ®ä»¥æ£€æŸ¥æ€»æ•°...")
            first_page_result = await self.extract_data_from_api()
            
            if not first_page_result['success']:
                self.logger.error("âŒ ç¬¬ä¸€é¡µæ•°æ®è·å–å¤±è´¥")
                return {"success": False, "action": "error", "message": "ç¬¬ä¸€é¡µæ•°æ®è·å–å¤±è´¥"}
            
            # æ£€æŸ¥æ˜¯å¦æœ‰æ•°æ®
            if not first_page_result['data']:
                self.logger.warning("âš ï¸ å½“å‰æ—¥æœŸæ²¡æœ‰ä¸šåŠ¡æ•°æ®")
                return {"success": True, "action": "no_data", "message": "å½“å‰æ—¥æœŸæ²¡æœ‰ä¸šåŠ¡æ•°æ®ï¼Œè¯·æ ¸æŸ¥æ—¥æœŸ"}
            
            # è·å–ç½‘ç«™ä¸Šçš„æ€»æ•°æ®é‡
            website_total = first_page_result.get('total', 0)
            self.logger.info(f"ğŸ“Š ç½‘ç«™æ˜¾ç¤ºæ€»æ•°æ®é‡: {website_total} æ¡")
            
            # å¯¹æ¯”æ•°æ®é‡
            if current_db_count == website_total and current_db_count > 0:
                self.logger.info("âœ… æ•°æ®å·²æ˜¯æœ€æ–°ï¼Œæ— éœ€åŒæ­¥")
                return {"success": True, "action": "no_sync", "message": "æ•°æ®å·²æ˜¯æœ€æ–°ï¼Œæ— éœ€åŒæ­¥", "total": current_db_count}
            
            # éœ€è¦åŒæ­¥æ•°æ®
            self.logger.info(f"ğŸ”„ éœ€è¦åŒæ­¥æ•°æ®: æ•°æ®åº“ {current_db_count} æ¡ï¼Œç½‘ç«™ {website_total} æ¡")
            
            # æå–æ‰€æœ‰é¡µé¢æ•°æ®
            all_data = await self.extract_all_pages_data_from_api()
            if not all_data:
                self.logger.error("âŒ æ²¡æœ‰æå–åˆ°æ•°æ®")
                return {"success": False, "action": "error", "message": "æ²¡æœ‰æå–åˆ°æ•°æ®"}
            
            # æ•°æ®å»é‡ï¼ˆåŸºäºIDå­—æ®µï¼‰
            unique_data = await self.deduplicate_data(all_data)
            
            # ä¿å­˜åˆ°æ•°æ®åº“
            db_result = await self.save_to_database(unique_data)
            
            # åŒæ­¥é—¨åº—åˆ°é…ç½®æ•°æ®åº“
            await self.sync_stores_to_config(unique_data)
            
            # å¯é€‰ï¼šä¿å­˜åˆ°CSVæ–‡ä»¶ä½œä¸ºå¤‡ä»½ï¼ˆå·²æ³¨é‡Šï¼Œç•™ä½œå¤‡ç”¨ï¼‰
            # csv_file = await self.save_api_data_to_csv(unique_data)
            
            if db_result > 0:
                self.logger.info(f"ğŸ‰ æ•°æ®åŒæ­¥å®Œæˆï¼æ–°å¢æ•°æ®åº“è®°å½•: {db_result}æ¡")
                # if csv_file:
                #     self.logger.info(f"ğŸ“„ CSVå¤‡ä»½æ–‡ä»¶: {csv_file}")
                return {"success": True, "action": "sync", "message": "æ•°æ®åŒæ­¥å®Œæˆ", "total": db_result}
            else:
                # æ£€æŸ¥æ˜¯å¦æ˜¯å› ä¸ºç½‘ç«™æ²¡æœ‰æ•°æ®å¯¼è‡´çš„
                if website_total == 0:
                    self.logger.warning("âš ï¸ ç½‘ç«™æ²¡æœ‰æ•°æ®ï¼Œæ— æ³•åŒæ­¥")
                    return {"success": True, "action": "no_data", "message": "å½“å‰æ—¥æœŸæ²¡æœ‰ä¸šåŠ¡æ•°æ®ï¼Œè¯·æ ¸æŸ¥æ—¥æœŸ"}
                else:
                    self.logger.info(f"ğŸ“‹ æ•°æ®åŒæ­¥å®Œæˆï¼æ•°æ®å·²æ˜¯æœ€æ–°çŠ¶æ€ï¼Œæ— æ–°è®°å½•éœ€è¦æ·»åŠ ")
                    return {"success": True, "action": "sync", "message": "æ•°æ®å·²æ˜¯æœ€æ–°çŠ¶æ€", "total": 0}
                
        except Exception as e:
            self.logger.error(f"âŒ æ™ºèƒ½æ•°æ®æå–å¼‚å¸¸: {e}")
            return {"success": False, "action": "error", "message": f"æ™ºèƒ½æ•°æ®æå–å¼‚å¸¸: {str(e)}"}

    async def full_api_data_extraction(self) -> bool:
        """å®Œæ•´çš„APIæ•°æ®æå–æµç¨‹"""
        try:
            self.logger.info("ğŸš€ å¼€å§‹å®Œæ•´çš„APIæ•°æ®æå–æµç¨‹...")
            
            # æ‰§è¡Œæœç´¢
            search_result = await self.set_date_and_search()
            if not search_result:
                self.logger.error("âŒ æœç´¢å¤±è´¥")
                return False
            
            # ç«‹å³å°è¯•è·å–ç¬¬ä¸€é¡µæ•°æ®
            self.logger.info("ğŸ“„ å°è¯•è·å–ç¬¬ä¸€é¡µæ•°æ®...")
            first_page_result = await self.extract_data_from_api()
            
            if first_page_result['success']:
                if first_page_result['data']:
                    self.logger.info(f"âœ… æˆåŠŸè·å–ç¬¬ä¸€é¡µæ•°æ®: {len(first_page_result['data'])} æ¡è®°å½•")
                    
                    # æå–æ‰€æœ‰é¡µé¢æ•°æ®
                    all_data = await self.extract_all_pages_data_from_api()
                    if not all_data:
                        self.logger.error("âŒ æ²¡æœ‰æå–åˆ°æ•°æ®")
                        return False
                else:
                    # æˆåŠŸè·å–ä½†æ•°æ®ä¸ºç©ºï¼Œè¯´æ˜æ²¡æœ‰ä¸šåŠ¡æ•°æ®
                    self.logger.warning("âš ï¸ å½“å‰æ—¥æœŸæ²¡æœ‰ä¸šåŠ¡æ•°æ®")
                    print("âš ï¸ å½“å‰æ—¥æœŸæ²¡æœ‰ä¸šåŠ¡æ•°æ®")
                    return False
            else:
                self.logger.error("âŒ ç¬¬ä¸€é¡µæ•°æ®è·å–å¤±è´¥")
                return False
            
            # æ•°æ®å»é‡ï¼ˆåŸºäºIDå­—æ®µï¼‰
            unique_data = await self.deduplicate_data(all_data)
            
            # ä¿å­˜åˆ°æ•°æ®åº“
            db_result = await self.save_to_database(unique_data)
            
            # åŒæ­¥é—¨åº—åˆ°é…ç½®æ•°æ®åº“
            await self.sync_stores_to_config(unique_data)
            
            # å¯é€‰ï¼šä¿å­˜åˆ°CSVæ–‡ä»¶ä½œä¸ºå¤‡ä»½ï¼ˆå·²æ³¨é‡Šï¼Œç•™ä½œå¤‡ç”¨ï¼‰
            # csv_file = await self.save_api_data_to_csv(unique_data)
            
            if db_result > 0:
                self.logger.info(f"ğŸ‰ APIæ•°æ®æå–å®Œæˆï¼æ–°å¢æ•°æ®åº“è®°å½•: {db_result}æ¡")
                print(f"ğŸ‰ APIæ•°æ®æå–å®Œæˆï¼æ–°å¢æ•°æ®åº“è®°å½•: {db_result}æ¡")
                # if csv_file:
                #     self.logger.info(f"ğŸ“„ CSVå¤‡ä»½æ–‡ä»¶: {csv_file}")
                return True
            else:
                self.logger.info(f"ğŸ“‹ APIæ•°æ®æå–å®Œæˆï¼æ•°æ®å·²æ˜¯æœ€æ–°çŠ¶æ€ï¼Œæ— æ–°è®°å½•éœ€è¦æ·»åŠ ")
                print(f"ğŸ“‹ APIæ•°æ®æå–å®Œæˆï¼æ•°æ®å·²æ˜¯æœ€æ–°çŠ¶æ€ï¼Œæ— æ–°è®°å½•éœ€è¦æ·»åŠ ")
                return True
                
        except Exception as e:
            self.logger.error(f"âŒ å®Œæ•´APIæ•°æ®æå–å¤±è´¥: {e}")
            return False
    
    async def save_to_database(self, data: list) -> int:
        """å°†æ•°æ®ä¿å­˜åˆ°æ•°æ®åº“"""
        try:
            if not data:
                self.logger.warning("æ²¡æœ‰æ•°æ®éœ€è¦ä¿å­˜åˆ°æ•°æ®åº“")
                return 0
            
            # è·å–æ•°æ®åº“ç®¡ç†å™¨
            db_manager = get_db_manager()
            
            # è®¡ç®—ç›®æ ‡æ—¥æœŸï¼Œä¸çˆ¬å–æ—¥æœŸä¿æŒä¸€è‡´
            if self.target_date:
                # ä½¿ç”¨æŒ‡å®šçš„ç›®æ ‡æ—¥æœŸ
                target_date_obj = datetime.strptime(self.target_date, '%Y-%m-%d')
                yesterday = target_date_obj
            else:
                # ä½¿ç”¨é»˜è®¤æ—¥æœŸï¼ˆå‰å¤©çš„æ—¥æœŸï¼‰
                yesterday = datetime.now() - timedelta(days=2)
            
            # æ’å…¥æ•°æ®ï¼ˆä¼šè‡ªåŠ¨å»é‡ï¼‰ï¼Œä½¿ç”¨æ˜¨å¤©çš„æ—¥æœŸ
            self.logger.info(f"ğŸ“Š å‡†å¤‡ä¿å­˜ {len(data)} æ¡è®°å½•åˆ°æ•°æ®åº“ï¼ˆæ—¥æœŸ: {yesterday.strftime('%Y-%m-%d')}ï¼‰")
            print(f"ğŸ“Š å‡†å¤‡ä¿å­˜ {len(data)} æ¡è®°å½•åˆ°æ•°æ®åº“ï¼ˆæ—¥æœŸ: {yesterday.strftime('%Y-%m-%d')}ï¼‰")
            
            inserted_count = db_manager.insert_data(data, date=yesterday)
            
            self.logger.info(f"âœ… æˆåŠŸä¿å­˜ {inserted_count} æ¡è®°å½•åˆ°æ•°æ®åº“ï¼ˆæ—¥æœŸ: {yesterday.strftime('%Y-%m-%d')}ï¼‰")
            print(f"âœ… æˆåŠŸä¿å­˜ {inserted_count} æ¡è®°å½•åˆ°æ•°æ®åº“ï¼ˆæ—¥æœŸ: {yesterday.strftime('%Y-%m-%d')}ï¼‰")
            
            # æ¸…ç†æ—§æ•°æ®åº“ï¼ˆä¿ç•™è¿‘1ä¸ªæœˆï¼‰
            db_manager.cleanup_old_databases(keep_months=1)
            
            return inserted_count
            
        except Exception as e:
            self.logger.error(f"âŒ ä¿å­˜åˆ°æ•°æ®åº“å¤±è´¥: {e}")
            return 0
    
    async def deduplicate_data(self, data: list) -> list:
        """æ•°æ®å»é‡"""
        try:
            if not data:
                return data
            
            # å°è¯•æ‰¾åˆ°IDå­—æ®µè¿›è¡Œå»é‡
            id_fields = ['id', 'ID', 'Id', '_id', 'uuid', 'key', 'objectKey']
            id_field = None
            
            if data and isinstance(data[0], dict):
                for field in id_fields:
                    if field in data[0]:
                        id_field = field
                        break
            
            if id_field:
                # åŸºäºIDå­—æ®µå»é‡
                seen_ids = set()
                unique_data = []
                
                for item in data:
                    item_id = item.get(id_field)
                    if item_id not in seen_ids:
                        seen_ids.add(item_id)
                        unique_data.append(item)
                
                self.logger.info(f"ğŸ”„ åŸºäº'{id_field}'å­—æ®µå»é‡: {len(data)} -> {len(unique_data)} æ¡è®°å½•")
                return unique_data
            else:
                # å¦‚æœæ²¡æœ‰IDå­—æ®µï¼ŒåŸºäºæ•´æ¡è®°å½•å»é‡
                unique_data = []
                seen_records = set()
                
                for item in data:
                    # å°†å­—å…¸è½¬æ¢ä¸ºå¯å“ˆå¸Œçš„å­—ç¬¦ä¸²
                    record_str = json.dumps(item, sort_keys=True, ensure_ascii=False)
                    if record_str not in seen_records:
                        seen_records.add(record_str)
                        unique_data.append(item)
                
                self.logger.info(f"ğŸ”„ åŸºäºå®Œæ•´è®°å½•å»é‡: {len(data)} -> {len(unique_data)} æ¡è®°å½•")
                return unique_data
                
        except Exception as e:
            self.logger.error(f"âŒ æ•°æ®å»é‡å¤±è´¥: {e}")
            return data
    
    async def take_screenshot(self, filename: str = "screenshot.png") -> bool:
        """æˆªå›¾ä¿å­˜"""
        try:
            if not self.page:
                return False
            
            await self.page.screenshot(path=filename, full_page=True)
            self.logger.info(f"æˆªå›¾ä¿å­˜æˆåŠŸ: {filename}")
            return True
            
        except Exception as e:
            self.logger.error(f"æˆªå›¾å¤±è´¥: {e}")
            return False
    
    async def close(self):
        """å…³é—­æµè§ˆå™¨å’Œèµ„æº"""
        try:
            # å®‰å…¨å…³é—­é¡µé¢
            if hasattr(self, 'page') and self.page:
                try:
                    await self.page.close()
                    self.page = None
                except Exception as e:
                    self.logger.warning(f"å…³é—­é¡µé¢æ—¶å‡ºé”™: {e}")
            
            # å®‰å…¨å…³é—­ä¸Šä¸‹æ–‡
            if hasattr(self, 'context') and self.context:
                try:
                    await self.context.close()
                    self.context = None
                except Exception as e:
                    self.logger.warning(f"å…³é—­ä¸Šä¸‹æ–‡æ—¶å‡ºé”™: {e}")
            
            # å®‰å…¨å…³é—­æµè§ˆå™¨
            if hasattr(self, 'browser') and self.browser:
                try:
                    await self.browser.close()
                    self.browser = None
                except Exception as e:
                    self.logger.warning(f"å…³é—­æµè§ˆå™¨æ—¶å‡ºé”™: {e}")
            
            # åœæ­¢ playwright
            if hasattr(self, 'playwright') and self.playwright:
                try:
                    await self.playwright.stop()
                    self.playwright = None
                except Exception as e:
                    self.logger.warning(f"åœæ­¢playwrightæ—¶å‡ºé”™: {e}")
            
            self.logger.info("æµè§ˆå™¨èµ„æºå·²å…³é—­")
            
        except Exception as e:
            self.logger.error(f"å…³é—­èµ„æºæ—¶å‡ºé”™: {e}")


async def main():
    """ä¸»å‡½æ•°ç¤ºä¾‹"""
    crawler = KSXCrawler(headless=False)  # è®¾ç½®ä¸ºFalseå¯ä»¥çœ‹åˆ°æµè§ˆå™¨æ“ä½œè¿‡ç¨‹
    
    try:
        # æ‰§è¡Œç™»å½•
        success = await crawler.login()
        
        if success:
            print("ç™»å½•æˆåŠŸï¼")
            
            # æ‰§è¡Œå®Œæ•´çš„APIæ•°æ®æå–
            extraction_success = await crawler.full_api_data_extraction()
            
            if extraction_success:
                print("æ•°æ®æå–å®Œæˆï¼")
            else:
                print("æ•°æ®æå–å¤±è´¥ï¼")
            
            # ç­‰å¾…ç”¨æˆ·æŸ¥çœ‹
            input("æŒ‰å›è½¦é”®ç»§ç»­...")
        else:
            print("ç™»å½•å¤±è´¥ï¼")
            
    except KeyboardInterrupt:
        print("\nç”¨æˆ·ä¸­æ–­æ“ä½œ")
    except Exception as e:
        print(f"ç¨‹åºå¼‚å¸¸: {e}")
    finally:
        await crawler.close()


if __name__ == "__main__":
    asyncio.run(main())
