#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ•°æ®åº“ç®¡ç†å™¨
è´Ÿè´£SQLiteæ•°æ®åº“çš„åˆ›å»ºã€ç®¡ç†å’Œæ¸…ç†
"""

import sqlite3
import json
import os
import shutil
import sys
from datetime import datetime, timedelta
from pathlib import Path
from typing import List, Dict, Any, Optional
# å°è¯•å¯¼å…¥loguruï¼Œå¦‚æœå¤±è´¥åˆ™ä½¿ç”¨æ ‡å‡†logging
try:
    from loguru import logger
    LOGGER_AVAILABLE = True
except ImportError:
    import logging
    logging.basicConfig(level=logging.INFO)
    logger = logging.getLogger(__name__)
    LOGGER_AVAILABLE = False
    print("è­¦å‘Š: loguruä¸å¯ç”¨ï¼Œä½¿ç”¨æ ‡å‡†loggingæ¨¡å—")

def get_database_dir():
    """è·å–æ•°æ®åº“ç›®å½•ï¼Œæ”¯æŒæ‰“åŒ…åçš„åº”ç”¨"""
    # é¦–å…ˆæ£€æŸ¥ç¯å¢ƒå˜é‡
    env_db_dir = os.environ.get('KSX_DATABASE_DIR')
    if env_db_dir:
        print(f"ğŸ” è°ƒè¯•ï¼šä½¿ç”¨ç¯å¢ƒå˜é‡æŒ‡å®šçš„æ•°æ®åº“ç›®å½•: {env_db_dir}")
        return env_db_dir
    
    if getattr(sys, 'frozen', False):
        # PyInstalleræ‰“åŒ…åçš„æƒ…å†µ
        print(f"ğŸ” è°ƒè¯•ï¼šsys.executable = {sys.executable}")
        print(f"ğŸ” è°ƒè¯•ï¼šsys.frozen = {getattr(sys, 'frozen', False)}")
        
        # å°è¯•å¤šç§æ–¹æ³•æ‰¾åˆ°æ­£ç¡®çš„åº”ç”¨ç›®å½•
        executable_path = Path(sys.executable)
        print(f"ğŸ” è°ƒè¯•ï¼šexecutable_path = {executable_path}")
        
        # æ–¹æ³•1ï¼šå°è¯•ä»ä¸´æ—¶ç›®å½•å‘ä¸ŠæŸ¥æ‰¾.appç›®å½•
        current_path = executable_path
        app_dir = None
        
        # å‘ä¸ŠæŸ¥æ‰¾æœ€å¤š5å±‚ç›®å½•
        for i in range(5):
            print(f"ğŸ” è°ƒè¯•ï¼šæ£€æŸ¥è·¯å¾„ {i}: {current_path}")
            if current_path.name.endswith('.app'):
                app_dir = current_path
                print(f"ğŸ” è°ƒè¯•ï¼šæ‰¾åˆ°.appç›®å½•: {app_dir}")
                break
            if current_path.parent == current_path:  # åˆ°è¾¾æ ¹ç›®å½•
                break
            current_path = current_path.parent
        
        if app_dir:
            database_dir = app_dir / "database"
            print(f"ğŸ” è°ƒè¯•ï¼šä½¿ç”¨.appç›®å½•: {database_dir}")
        else:
            # æ–¹æ³•2ï¼šå¦‚æœæ‰¾ä¸åˆ°.appç›®å½•ï¼Œå°è¯•ä½¿ç”¨å›ºå®šçš„distè·¯å¾„
            # ä»executableè·¯å¾„ä¸­æå–é¡¹ç›®è·¯å¾„
            if "KSXé—¨åº—ç®¡ç†ç³»ç»Ÿ" in str(executable_path):
                # å¦‚æœè·¯å¾„ä¸­åŒ…å«åº”ç”¨åç§°ï¼Œå°è¯•æ‰¾åˆ°distç›®å½•
                parts = executable_path.parts
                for i, part in enumerate(parts):
                    if part == "dist":
                        dist_dir = Path(*parts[:i+1])
                        app_name = "KSXé—¨åº—ç®¡ç†ç³»ç»Ÿ.app"
                        app_dir = dist_dir / app_name
                        if app_dir.exists():
                            database_dir = app_dir / "database"
                            print(f"ğŸ” è°ƒè¯•ï¼šä½¿ç”¨å›ºå®šdistè·¯å¾„: {database_dir}")
                            break
                else:
                    # å¦‚æœæ‰¾ä¸åˆ°distç›®å½•ï¼Œä½¿ç”¨ç”¨æˆ·ç›®å½•ä½œä¸ºå¤‡ç”¨
                    database_dir = Path.home() / "KSX_Database"
                    print(f"ğŸ” è°ƒè¯•ï¼šæ‰¾ä¸åˆ°distç›®å½•ï¼Œä½¿ç”¨ç”¨æˆ·ç›®å½•: {database_dir}")
            else:
                # å¦‚æœè·¯å¾„ä¸­ä¸åŒ…å«åº”ç”¨åç§°ï¼Œä½¿ç”¨ç”¨æˆ·ç›®å½•
                database_dir = Path.home() / "KSX_Database"
                print(f"ğŸ” è°ƒè¯•ï¼šè·¯å¾„ä¸­ä¸åŒ…å«åº”ç”¨åç§°ï¼Œä½¿ç”¨ç”¨æˆ·ç›®å½•: {database_dir}")
        
        return str(database_dir)
    else:
        # å¼€å‘ç¯å¢ƒ
        current_file = Path(__file__).resolve()
        project_root = current_file.parent.parent
        return str(project_root / "database")


class DatabaseManager:
    """æ•°æ®åº“ç®¡ç†å™¨"""
    
    def __init__(self, base_dir: str = None):
        """
        åˆå§‹åŒ–æ•°æ®åº“ç®¡ç†å™¨
        
        Args:
            base_dir: æ•°æ®åº“æ ¹ç›®å½•ï¼Œé»˜è®¤ä¸ºé¡¹ç›®æ ¹ç›®å½•ä¸‹çš„database
        """
        if base_dir is None:
            # ä½¿ç”¨æ­£ç¡®çš„æ•°æ®åº“ç›®å½•
            base_dir = get_database_dir()
        
        self.base_dir = Path(base_dir)
        print(f"ğŸ” è°ƒè¯•ï¼šå°è¯•åˆ›å»ºæ•°æ®åº“ç›®å½•: {self.base_dir}")
        
        try:
            self.base_dir.mkdir(parents=True, exist_ok=True)
            print(f"âœ… æ•°æ®åº“ç›®å½•åˆ›å»ºæˆåŠŸ: {self.base_dir}")
        except Exception as e:
            print(f"âŒ æ•°æ®åº“ç›®å½•åˆ›å»ºå¤±è´¥: {e}")
            # å¦‚æœåˆ›å»ºå¤±è´¥ï¼Œå°è¯•ä½¿ç”¨ç”¨æˆ·ç›®å½•
            import os
            fallback_dir = Path.home() / "KSX_Database"
            print(f"ğŸ” è°ƒè¯•ï¼šå°è¯•ä½¿ç”¨å¤‡ç”¨ç›®å½•: {fallback_dir}")
            try:
                fallback_dir.mkdir(parents=True, exist_ok=True)
                self.base_dir = fallback_dir
                print(f"âœ… å¤‡ç”¨æ•°æ®åº“ç›®å½•åˆ›å»ºæˆåŠŸ: {self.base_dir}")
            except Exception as e2:
                print(f"âŒ å¤‡ç”¨æ•°æ®åº“ç›®å½•ä¹Ÿåˆ›å»ºå¤±è´¥: {e2}")
                raise e2
        
        # è°ƒè¯•ï¼šè®°å½•base_dirè·¯å¾„
        logger.info(f"DatabaseManageråˆå§‹åŒ–: base_dir = {self.base_dir}")
        
        # å›ºå®šçš„æ•°æ®è¡¨ç»“æ„å®šä¹‰
        self.schema = self._get_schema()
        
    def _get_schema(self) -> List[Dict[str, Any]]:
        """è·å–æ•°æ®è¡¨ç»“æ„å®šä¹‰ - æ ¹æ®data.jsonå®Œæ•´è®¾è®¡"""
        return [
            # åŸºç¡€å­—æ®µ
            {"name": "rawId", "label": "åŸå§‹æ•°æ®ID", "type": "TEXT"},
            {"name": "area", "label": "åŒºåŸŸ", "type": "TEXT"},
            {"name": "createDateShow", "label": "æ—¥æœŸ", "type": "TEXT"},
            {"name": "MDShow", "label": "é—¨åº—åç§°", "type": "TEXT"},
            {"name": "totalScore", "label": "æœ€ç»ˆå¾—åˆ†", "type": "REAL"},
            
            # å–æ¶ˆå’Œé€€å•ç›¸å…³
            {"name": "monthlyCanceledRate", "label": "æœˆç´¯è®¡å–æ¶ˆç‡", "type": "TEXT"},
            {"name": "dailyCanceledRate", "label": "å½“æ—¥å–æ¶ˆç‡", "type": "TEXT"},
            {"name": "monthlyMerchantRefundRate", "label": "æœˆç´¯è®¡å•†è´£é€€å•ç‡", "type": "TEXT"},
            {"name": "monthlyOosRefundRate", "label": "æœˆç´¯è®¡ç¼ºè´§é€€æ¬¾ç‡", "type": "TEXT"},
            {"name": "monthlyJdOosRate", "label": "æœˆç´¯è®¡äº¬ä¸œç§’é€ç¼ºè´§å‡ºç‡", "type": "TEXT"},
            {"name": "monthlyBadReviews", "label": "æœˆç´¯è®¡å·®è¯„æ€»æ•°", "type": "TEXT"},
            {"name": "monthlyBadReviewRate", "label": "æœˆç´¯è®¡å·®è¯„ç‡", "type": "TEXT"},
            {"name": "monthlyPartialRefundRate", "label": "æœˆç´¯è®¡éƒ¨åˆ†é€€æ¬¾ç‡", "type": "TEXT"},
            
            # è¯„åˆ†ç›¸å…³
            {"name": "dailyMeituanRating", "label": "å½“æ—¥ç¾å›¢è¯„åˆ†", "type": "TEXT"},
            {"name": "dailyElemeRating", "label": "å½“æ—¥é¥¿äº†ä¹ˆè¯„åˆ†", "type": "TEXT"},
            {"name": "dailyMeituanReplyRate", "label": "å½“æ—¥ç¾å›¢è¿‘7æ—¥é¦–æ¡æ¶ˆæ¯1åˆ†é’Ÿäººå·¥å›å¤ç‡", "type": "TEXT"},
            {"name": "effectReply", "label": "æœ‰æ•ˆå›å¤", "type": "TEXT"},
            {"name": "monthlyMeituanPunctualityRate", "label": "æœˆç´¯è®¡ç¾å›¢é…é€å‡†æ—¶ç‡", "type": "TEXT"},
            {"name": "monthlyElemeOntimeRate", "label": "æœˆç´¯è®¡é¥¿äº†ä¹ˆåŠæ—¶é€è¾¾ç‡", "type": "TEXT"},
            {"name": "monthlyJdFulfillmentRate", "label": "æœˆç´¯è®¡äº¬ä¸œç§’é€è®¢å•å±¥çº¦ç‡", "type": "TEXT"},
            {"name": "meituanComprehensiveExperienceDivision", "label": "ç¾å›¢ç»¼åˆä½“ä½“éªŒåˆ†", "type": "TEXT"},
            
            # åº“å­˜ç›¸å…³
            {"name": "monthlyAvgStockRate", "label": "æœˆå¹³å‡æœ‰è´§ç‡", "type": "TEXT"},
            {"name": "monthlyAvgTop500StockRate", "label": "æœˆå¹³å‡TOP500æœ‰è´§ç‡", "type": "TEXT"},
            {"name": "monthlyAvgDirectStockRate", "label": "æœˆå¹³å‡ç›´é…ç›´é€æœ‰è´§ç‡", "type": "TEXT"},
            {"name": "dailyTop500StockRate", "label": "å½“æ—¥TOP500æœ‰è´§ç‡", "type": "TEXT"},
            {"name": "dailyWarehouseSoldOut", "label": "å½“æ—¥ä»“é…å”®ç½„æ•°", "type": "TEXT"},
            {"name": "dailyWarehouseStockRate", "label": "å½“æ—¥ä»“é…æœ‰è´§ç‡", "type": "TEXT"},
            {"name": "dailyDirectSoldOut", "label": "å½“æ—¥ç›´é€å”®ç½„æ•°", "type": "TEXT"},
            {"name": "dailyDirectStockRate", "label": "å½“æ—¥ç›´é€æœ‰è´§ç‡", "type": "TEXT"},
            {"name": "dailyHybridSoldOut", "label": "å½“æ—¥ç›´é…å”®ç½„æ•°", "type": "TEXT"},
            {"name": "dailyStockAvailability", "label": "å½“æ—¥æœ‰è´§ç‡", "type": "TEXT"},
            {"name": "dailyHybridStockRate", "label": "å½“æ—¥ç›´é…æœ‰è´§ç‡", "type": "TEXT"},
            {"name": "stockNoLocation", "label": "æœ‰åº“å­˜æ— åº“ä½æ•°", "type": "TEXT"},
            {"name": "expiryManagement", "label": "æ•ˆæœŸç®¡ç†", "type": "TEXT"},
            {"name": "inventoryLockOrders", "label": "åº“å­˜é”å®šå•æ•°", "type": "TEXT"},
            {"name": "trainingCompleted", "label": "åŸ¹è®­å®Œç»“", "type": "TEXT"},
            
            # å·¥æ—¶å’ŒæŸè€—ç›¸å…³
            {"name": "monthlyManhourPer100Orders", "label": "æœˆç´¯è®¡ç™¾å•ç¼–åˆ¶å·¥æ—¶", "type": "REAL"},
            {"name": "monthlyTotalLoss", "label": "æœˆç´¯è®¡ç»¼åˆæŸæº¢é¢", "type": "REAL"},
            {"name": "monthlyTotalLossRate", "label": "æœˆç´¯è®¡ç»¼åˆæŸæº¢ç‡", "type": "TEXT"},
            {"name": "monthlyAvgDeliveryFee", "label": "æœ¬æœˆç´¯è®¡å•å‡é…é€è´¹", "type": "REAL"},
            {"name": "dailyAvgDeliveryFee", "label": "å½“æ—¥å•å‡é…é€è´¹", "type": "REAL"},
            
            # å¾—åˆ†ç›¸å…³
            {"name": "monthlyCumulativeCancelRateScore", "label": "æœˆç´¯è®¡å–æ¶ˆç‡å¾—åˆ†", "type": "TEXT"},
            {"name": "monthlyMerchantLiabilityRefundRateScore", "label": "æœˆç´¯è®¡å•†è´£é€€å•ç‡å¾—åˆ†", "type": "TEXT"},
            {"name": "monthlyStockoutRefundRateScore", "label": "æœˆç´¯è®¡ç¼ºè´§é€€æ¬¾ç‡å¾—åˆ†", "type": "TEXT"},
            {"name": "monthlyNegativeReviewRateScore", "label": "æœˆç´¯è®¡å·®è¯„ç‡å¾—åˆ†", "type": "TEXT"},
            {"name": "monthlyPartialRefundRateScore", "label": "æœˆç´¯è®¡éƒ¨åˆ†é€€æ¬¾ç‡å¾—åˆ†", "type": "TEXT"},
            {"name": "dailyMeituanRatingScore", "label": "å½“æ—¥ç¾å›¢è¯„åˆ†å¾—åˆ†", "type": "TEXT"},
            {"name": "dailyElemeRatingScore", "label": "å½“æ—¥é¥¿äº†ä¹ˆè¯„åˆ†å¾—åˆ†", "type": "TEXT"},
            {"name": "monthlyMeituanDeliveryPunctualityRateScore", "label": "æœˆç´¯è®¡ç¾å›¢é…é€å‡†æ—¶ç‡å¾—åˆ†", "type": "TEXT"},
            {"name": "monthlyElemeTimelyDeliveryRateScore", "label": "æœˆç´¯è®¡é¥¿äº†ä¹ˆåŠæ—¶é€è¾¾ç‡å¾—åˆ†", "type": "TEXT"},
            
            # é™æƒç›¸å…³
            {"name": "validReplyWeightingPenalty", "label": "æœ‰æ•ˆå›å¤é™æƒ", "type": "TEXT"},
            {"name": "monthlyAverageStockRateWeightingPenalty", "label": "æœˆå¹³å‡æœ‰è´§ç‡é™æƒ", "type": "TEXT"},
            {"name": "monthlyAverageTop500StockRateWeightingPenalty", "label": "æœˆå¹³å‡TOP500æœ‰è´§ç‡é™æƒ", "type": "TEXT"},
            {"name": "monthlyAverageDirectStockRateWeightingPenalty", "label": "æœˆå¹³å‡ç›´é…ç›´é€æœ‰è´§ç‡é™æƒ", "type": "TEXT"},
            {"name": "newProductComplianceListingWeightingPenalty", "label": "æ–°å“åˆè§„ä¸Šæ–°é™æƒ", "type": "TEXT"},
            {"name": "expiryManagementWeightingPenalty", "label": "æ•ˆæœŸç®¡ç†é™æƒ", "type": "TEXT"},
            {"name": "inventoryLockWeightingPenalty", "label": "åº“å­˜é”å®šé™æƒ", "type": "TEXT"},
            {"name": "monthlyCumulativeHundredOrdersManhourWeightingPenalty", "label": "æœˆç´¯è®¡ç™¾å•ç¼–åˆ¶å·¥æ—¶é™æƒ", "type": "TEXT"},
            {"name": "totalScoreWithoutWeightingPenalty", "label": "æ€»å¾—åˆ†ï¼ˆä¸å«é™æƒï¼‰", "type": "TEXT"},
            {"name": "monthlyCumulativeMerchantLiabilityRefundRateWeightingPenalty", "label": "æœˆç´¯è®¡å•†è´£é€€å•ç‡é™æƒ", "type": "TEXT"},
            {"name": "monthlyCumulativeOutOfStockRefundRateWeightingPenalty", "label": "æœˆç´¯è®¡ç¼ºè´§é€€æ¬¾ç‡é™æƒ", "type": "TEXT"},
            {"name": "meituanComplexExperienceScoreWeightingPenalty", "label": "ç¾å›¢ç»¼åˆä½“ä½“éªŒåˆ†é™æƒ", "type": "TEXT"},
            {"name": "meituanRatingWeightingPenalty", "label": "ç¾å›¢è¯„åˆ†é™æƒ", "type": "TEXT"},
            {"name": "elemeRatingWeightingPenalty", "label": "é¥¿äº†ä¹ˆè¯„åˆ†é™æƒ", "type": "TEXT"},
            {"name": "partialRefundWeightingPenalty", "label": "éƒ¨åˆ†é€€æ¬¾é™æƒ", "type": "TEXT"},
            {"name": "trainingCompletedWeightingPenalty", "label": "åŸ¹è®­å®Œç»“é™æƒ", "type": "TEXT"},
            {"name": "totalWeightingPenalty", "label": "æ€»é™æƒ", "type": "TEXT"}
        ]
    
    def _generate_create_table_sql(self) -> str:
        """ç”Ÿæˆåˆ›å»ºè¡¨çš„SQLè¯­å¥"""
        sql_parts = [
            "CREATE TABLE IF NOT EXISTS ksx_data (",
            "    id INTEGER PRIMARY KEY AUTOINCREMENT,",  # è‡ªå¢ä¸»é”®
            "    created_at DATETIME DEFAULT CURRENT_TIMESTAMP,"
        ]
        
        # æ·»åŠ å…¶ä»–å­—æ®µ
        for column in self.schema:
            column_name = column.get('name', '')
            column_type = column.get('type', 'TEXT')
            if column_name and column_name.lower() != 'id':
                sql_parts.append(f"    {column_name} {column_type},")
        
        # ç§»é™¤æœ€åä¸€ä¸ªé€—å·å¹¶æ·»åŠ ç»“æŸæ‹¬å·
        if sql_parts[-1].endswith(','):
            sql_parts[-1] = sql_parts[-1][:-1]
        
        sql_parts.append(")")
        
        return "\n".join(sql_parts)
    
    def get_database_path(self, date: datetime = None) -> Path:
        """
        è·å–æŒ‡å®šæ—¥æœŸçš„æ•°æ®åº“æ–‡ä»¶è·¯å¾„
        
        Args:
            date: æ—¥æœŸï¼Œé»˜è®¤ä¸ºä»Šå¤©
            
        Returns:
            æ•°æ®åº“æ–‡ä»¶è·¯å¾„
        """
        if date is None:
            date = datetime.now()
            
        year_month = date.strftime("%Y-%m")
        day = date.strftime("%d")
        
        # åˆ›å»ºå¹´æœˆç›®å½•
        month_dir = self.base_dir / year_month
        month_dir.mkdir(exist_ok=True)
        
        # æ•°æ®åº“æ–‡ä»¶åï¼šksx_YYYY-MM-DD.db
        db_filename = f"ksx_{date.strftime('%Y-%m-%d')}.db"
        return month_dir / db_filename
    
    def create_database(self, date: datetime = None) -> str:
        """
        åˆ›å»ºæ•°æ®åº“å’Œè¡¨
        
        Args:
            date: æ—¥æœŸï¼Œé»˜è®¤ä¸ºä»Šå¤©
            
        Returns:
            æ•°æ®åº“æ–‡ä»¶è·¯å¾„
        """
        db_path = self.get_database_path(date)
        
        try:
            logger.info(f"ğŸ” è°ƒè¯•ï¼šå¼€å§‹åˆ›å»ºæ•°æ®åº“: {db_path}")
            print(f"ğŸ” è°ƒè¯•ï¼šå¼€å§‹åˆ›å»ºæ•°æ®åº“: {db_path}")
            
            # åˆ›å»ºæ•°æ®åº“è¿æ¥
            conn = sqlite3.connect(str(db_path))
            cursor = conn.cursor()
            
            # åˆ›å»ºè¡¨
            create_sql = self._generate_create_table_sql()
            logger.info(f"ğŸ” è°ƒè¯•ï¼šæ‰§è¡Œåˆ›å»ºè¡¨SQL: {create_sql[:200]}...")
            print(f"ğŸ” è°ƒè¯•ï¼šæ‰§è¡Œåˆ›å»ºè¡¨SQL: {create_sql[:200]}...")
            cursor.execute(create_sql)
            
            # åˆ›å»ºç´¢å¼•
            cursor.execute("CREATE INDEX IF NOT EXISTS idx_created_at ON ksx_data(created_at)")
            cursor.execute("CREATE INDEX IF NOT EXISTS idx_mdshow ON ksx_data(MDShow)")
            cursor.execute("CREATE INDEX IF NOT EXISTS idx_rawid ON ksx_data(rawId)")
            
            conn.commit()
            conn.close()
            
            logger.info(f"âœ… æ•°æ®åº“åˆ›å»ºæˆåŠŸ: {db_path}")
            print(f"âœ… æ•°æ®åº“åˆ›å»ºæˆåŠŸ: {db_path}")
            return str(db_path)
            
        except Exception as e:
            logger.error(f"åˆ›å»ºæ•°æ®åº“å¤±è´¥: {e}")
            raise
    
    def insert_data(self, data: List[Dict[str, Any]], date: datetime = None) -> int:
        """
        æ’å…¥æ•°æ®åˆ°æ•°æ®åº“
        
        Args:
            data: è¦æ’å…¥çš„æ•°æ®åˆ—è¡¨
            date: æ—¥æœŸï¼Œé»˜è®¤ä¸ºä»Šå¤©
            
        Returns:
            æˆåŠŸæ’å…¥çš„è®°å½•æ•°
        """
        if not data:
            logger.warning("æ²¡æœ‰æ•°æ®éœ€è¦æ’å…¥")
            return 0
            
        db_path = self.get_database_path(date)
        logger.info(f"ğŸ” è°ƒè¯•ï¼šæ•°æ®åº“è·¯å¾„: {db_path}")
        print(f"ğŸ” è°ƒè¯•ï¼šæ•°æ®åº“è·¯å¾„: {db_path}")
        
        # å¦‚æœæ•°æ®åº“ä¸å­˜åœ¨ï¼Œå…ˆåˆ›å»º
        if not db_path.exists():
            logger.info(f"ğŸ” è°ƒè¯•ï¼šæ•°æ®åº“ä¸å­˜åœ¨ï¼Œå¼€å§‹åˆ›å»º: {db_path}")
            print(f"ğŸ” è°ƒè¯•ï¼šæ•°æ®åº“ä¸å­˜åœ¨ï¼Œå¼€å§‹åˆ›å»º: {db_path}")
            self.create_database(date)
        else:
            logger.info(f"ğŸ” è°ƒè¯•ï¼šæ•°æ®åº“å·²å­˜åœ¨: {db_path}")
            print(f"ğŸ” è°ƒè¯•ï¼šæ•°æ®åº“å·²å­˜åœ¨: {db_path}")
        
        try:
            conn = sqlite3.connect(str(db_path))
            cursor = conn.cursor()
            
            inserted_count = 0
            
            for item in data:
                # ç¡®ä¿æœ‰åŸå§‹IDå­—æ®µ
                raw_id = item.get('ID') or item.get('id') or item.get('rawId')
                if not raw_id:
                    logger.warning("æ•°æ®é¡¹ç¼ºå°‘åŸå§‹IDå­—æ®µï¼Œè·³è¿‡")
                    continue
                
                # æ£€æŸ¥æ˜¯å¦å·²å­˜åœ¨ï¼ˆåŸºäºrawIdå»é‡ï¼‰
                cursor.execute("SELECT COUNT(*) FROM ksx_data WHERE rawId = ?", (raw_id,))
                if cursor.fetchone()[0] > 0:
                    logger.debug(f"è®°å½•å·²å­˜åœ¨ï¼Œè·³è¿‡: {raw_id}")
                    continue
                
                # å‡†å¤‡æ’å…¥æ•°æ®ï¼Œç¡®ä¿rawIdå­—æ®µ
                item_copy = item.copy()
                item_copy['rawId'] = raw_id
                
                # å‡†å¤‡æ’å…¥çš„åˆ—å’Œå€¼
                columns = []
                values = []
                
                for col in self.schema:
                    col_name = col['name']
                    if col_name in item_copy:
                        columns.append(col_name)
                        values.append(item_copy[col_name])
                    else:
                        # å¯¹äºç¼ºå¤±çš„å­—æ®µï¼Œæ’å…¥ç©ºå€¼
                        columns.append(col_name)
                        values.append(None)
                
                placeholders = ','.join(['?'] * len(columns))
                sql = f"INSERT INTO ksx_data ({','.join(columns)}) VALUES ({placeholders})"
                
                cursor.execute(sql, values)
                inserted_count += 1
            
            conn.commit()
            conn.close()
            
            logger.info(f"æˆåŠŸæ’å…¥ {inserted_count} æ¡è®°å½•åˆ° {db_path}")
            return inserted_count
            
        except Exception as e:
            logger.error(f"æ’å…¥æ•°æ®å¤±è´¥: {e}")
            import traceback
            logger.error(f"è¯¦ç»†é”™è¯¯ä¿¡æ¯: {traceback.format_exc()}")
            print(f"âŒ æ•°æ®åº“æ’å…¥å¤±è´¥: {e}")
            print(f"âŒ è¯¦ç»†é”™è¯¯ä¿¡æ¯: {traceback.format_exc()}")
            raise
    
    def query_data(self, 
                   date: datetime = None, 
                   mdshow_filter: str = None,
                   page: int = 1, 
                   page_size: int = 20) -> Dict[str, Any]:
        """
        æŸ¥è¯¢æ•°æ®
        
        Args:
            date: æ—¥æœŸï¼Œé»˜è®¤ä¸ºä»Šå¤©
            mdshow_filter: MDShowå­—æ®µçš„æ¨¡ç³ŠæŸ¥è¯¢æ¡ä»¶
            page: é¡µç ï¼Œä»1å¼€å§‹
            page_size: æ¯é¡µè®°å½•æ•°
            
        Returns:
            æŸ¥è¯¢ç»“æœï¼ŒåŒ…å«æ•°æ®å’Œåˆ†é¡µä¿¡æ¯
        """
        db_path = self.get_database_path(date)
        
        if not db_path.exists():
            return {
                'data': [],
                'total': 0,
                'page': page,
                'page_size': page_size,
                'total_pages': 0
            }
        
        try:
            conn = sqlite3.connect(str(db_path))
            conn.row_factory = sqlite3.Row  # ä½¿ç»“æœå¯ä»¥é€šè¿‡åˆ—åè®¿é—®
            cursor = conn.cursor()
            
            # æ„å»ºæŸ¥è¯¢æ¡ä»¶
            where_clause = ""
            params = []
            
            if mdshow_filter:
                where_clause = "WHERE MDShow LIKE ?"
                params.append(f"%{mdshow_filter}%")
            
            # è®¡ç®—æ€»è®°å½•æ•°
            count_sql = f"SELECT COUNT(*) FROM ksx_data {where_clause}"
            cursor.execute(count_sql, params)
            total = cursor.fetchone()[0]
            
            # è®¡ç®—åˆ†é¡µ
            total_pages = (total + page_size - 1) // page_size
            offset = (page - 1) * page_size
            
            # æŸ¥è¯¢æ•°æ®
            data_sql = f"""
                SELECT * FROM ksx_data 
                {where_clause}
                ORDER BY created_at ASC
                LIMIT ? OFFSET ?
            """
            cursor.execute(data_sql, params + [page_size, offset])
            
            rows = cursor.fetchall()
            data = [dict(row) for row in rows]
            
            conn.close()
            
            return {
                'data': data,
                'total': total,
                'page': page,
                'page_size': page_size,
                'total_pages': total_pages
            }
            
        except Exception as e:
            logger.error(f"æŸ¥è¯¢æ•°æ®å¤±è´¥: {e}")
            raise
    
    def cleanup_old_databases(self, keep_months: int = 1):
        """
        æ¸…ç†æ—§çš„æ•°æ®åº“æ–‡ä»¶
        
        Args:
            keep_months: ä¿ç•™æœ€è¿‘å¤šå°‘ä¸ªæœˆçš„æ•°æ®
        """
        try:
            cutoff_date = datetime.now() - timedelta(days=30 * keep_months)
            cutoff_month = cutoff_date.strftime("%Y-%m")
            
            deleted_dirs = []
            
            for month_dir in self.base_dir.iterdir():
                if month_dir.is_dir() and month_dir.name < cutoff_month:
                    shutil.rmtree(month_dir)
                    deleted_dirs.append(month_dir.name)
                    
            if deleted_dirs:
                logger.info(f"å·²åˆ é™¤æ—§æ•°æ®åº“ç›®å½•: {deleted_dirs}")
            else:
                logger.info("æ²¡æœ‰éœ€è¦æ¸…ç†çš„æ—§æ•°æ®åº“")
                
        except Exception as e:
            logger.error(f"æ¸…ç†æ—§æ•°æ®åº“å¤±è´¥: {e}")
    
    def get_database_info(self) -> Dict[str, Any]:
        """è·å–æ•°æ®åº“ä¿¡æ¯"""
        info = {
            'base_dir': str(self.base_dir),
            'months': [],
            'total_databases': 0,
            'total_size_mb': 0
        }
        
        try:
            total_size = 0
            total_dbs = 0
            
            for month_dir in sorted(self.base_dir.iterdir()):
                if not month_dir.is_dir():
                    continue
                    
                month_info = {
                    'month': month_dir.name,
                    'databases': [],
                    'size_mb': 0
                }
                
                month_size = 0
                for db_file in month_dir.glob("*.db"):
                    db_size = db_file.stat().st_size
                    month_size += db_size
                    total_size += db_size
                    total_dbs += 1
                    
                    month_info['databases'].append({
                        'name': db_file.name,
                        'size_mb': round(db_size / 1024 / 1024, 2),
                        'created': datetime.fromtimestamp(db_file.stat().st_ctime).isoformat()
                    })
                
                month_info['size_mb'] = round(month_size / 1024 / 1024, 2)
                info['months'].append(month_info)
            
            info['total_databases'] = total_dbs
            info['total_size_mb'] = round(total_size / 1024 / 1024, 2)
            
        except Exception as e:
            logger.error(f"è·å–æ•°æ®åº“ä¿¡æ¯å¤±è´¥: {e}")
            
        return info
    
    def get_stores(self) -> List[Dict[str, str]]:
        """
        è·å–é—¨åº—åˆ—è¡¨
        
        Returns:
            é—¨åº—åˆ—è¡¨ï¼ŒåŒ…å«nameå’Œvalueå­—æ®µ
        """
        stores = []
        
        # éå†æ‰€æœ‰æ•°æ®åº“æ–‡ä»¶ï¼Œæ”¶é›†é—¨åº—ä¿¡æ¯
        for db_file in self.base_dir.rglob("ksx_*.db"):
            try:
                conn = sqlite3.connect(str(db_file))
                conn.row_factory = sqlite3.Row
                cursor = conn.cursor()
                
                # æŸ¥è¯¢é—¨åº—åˆ—è¡¨
                cursor.execute("""
                    SELECT DISTINCT MDShow as name, MDShow as value
                    FROM ksx_data 
                    WHERE MDShow IS NOT NULL AND MDShow != ''
                    ORDER BY MDShow
                """)
                
                for row in cursor.fetchall():
                    store = dict(row)
                    if store not in stores:
                        stores.append(store)
                
                conn.close()
                
            except Exception as e:
                logger.warning(f"è¯»å–æ•°æ®åº“æ–‡ä»¶ {db_file} å¤±è´¥: {e}")
                continue
        
        return stores
    
    def execute_query(self, query: str, params: Dict[str, Any] = None) -> List[Dict[str, Any]]:
        """
        æ‰§è¡Œè‡ªå®šä¹‰æŸ¥è¯¢
        
        Args:
            query: SQLæŸ¥è¯¢è¯­å¥
            params: æŸ¥è¯¢å‚æ•°
            
        Returns:
            æŸ¥è¯¢ç»“æœåˆ—è¡¨
        """
        if params is None:
            params = {}
            
        results = []
        
        # éå†æ‰€æœ‰æ•°æ®åº“æ–‡ä»¶ï¼Œæ‰§è¡ŒæŸ¥è¯¢
        for db_file in self.base_dir.rglob("ksx_*.db"):
            try:
                conn = sqlite3.connect(str(db_file))
                conn.row_factory = sqlite3.Row
                cursor = conn.cursor()
                
                # æ‰§è¡ŒæŸ¥è¯¢
                cursor.execute(query, params)
                
                for row in cursor.fetchall():
                    results.append(dict(row))
                
                conn.close()
                
            except Exception as e:
                logger.warning(f"æ‰§è¡ŒæŸ¥è¯¢å¤±è´¥ {db_file}: {e}")
                continue
        
        return results


# å•ä¾‹æ¨¡å¼
_db_manager = None

def get_db_manager() -> DatabaseManager:
    """è·å–æ•°æ®åº“ç®¡ç†å™¨å•ä¾‹"""
    global _db_manager
    if _db_manager is None:
        _db_manager = DatabaseManager()
    return _db_manager


if __name__ == "__main__":
    # æµ‹è¯•ä»£ç 
    db_manager = DatabaseManager()
    
    # åˆ›å»ºæ•°æ®åº“
    db_path = db_manager.create_database()
    print(f"æ•°æ®åº“åˆ›å»ºæˆåŠŸ: {db_path}")
    
    # æµ‹è¯•æ’å…¥æ•°æ®
    test_data = [
        {
            'ID': 'test001',
            'MDShow': 'æµ‹è¯•é—¨åº—1',
            'area': '1åŒº',
            'totalScore': 85.5
        },
        {
            'ID': 'test002', 
            'MDShow': 'æµ‹è¯•é—¨åº—2',
            'area': '2åŒº',
            'totalScore': 90.0
        }
    ]
    
    inserted = db_manager.insert_data(test_data)
    print(f"æ’å…¥è®°å½•æ•°: {inserted}")
    
    # æµ‹è¯•æŸ¥è¯¢æ•°æ®
    result = db_manager.query_data(mdshow_filter="æµ‹è¯•")
    print(f"æŸ¥è¯¢ç»“æœ: {result}")
    
    # è·å–æ•°æ®åº“ä¿¡æ¯
    info = db_manager.get_database_info()
    print(f"æ•°æ®åº“ä¿¡æ¯: {info}")
